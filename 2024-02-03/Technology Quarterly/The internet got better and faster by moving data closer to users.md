###### The edge of tomorrow
# The internet got better and faster by moving data closer to users 
##### Now the same must happen with computing power 
![image](images/20240203_TQD003.jpg) 
> Jan 29th 2024 
Until 1995 MANY messages sent between internet users in Frankfurt could expect to go on quite a ride. If the sender and receiver used different internet service providers (ISPs), the message would make a return trip across the Atlantic Ocean, pulsing along thousands of kilometres of underwater fibre-optic cables before ending up just a few kilometres from where it started. This was, in a way, a triumph of abstraction. The users had no idea about the intercontinental detour (except perhaps for how long it took). But for the ISPs involved it was a royal pain. So three of them got together and, in the back room of a post office, installed a switch that linked their networks together. It was called the Deutsche Commercial Internet Exchange, or DE-CIX.
The internet is a network of networks. Internet exchanges are the portals where lots of those networks are linked to each other; switches connect devices within these networks. As the internet has grown, exchanges and their switches have become more numerous and vastly more impressive, allowing levels of performance that would have been unthinkable using old technology.
Tucked behind a mesh door in a data centre in Frankfurt sits a machine the size of a refrigerator. Hundreds of yellow, pink and aquamarine cables are plugged in neat rows and columns on its front. Flashing green lights adorn the cables, which are connected to servers that belong to a wide range of ISPs, cloud services and CDNs. During peak times (like nights when Champions League football matches are on) more than four terabits flow through this one machine each second—equivalent to over a million HD videos streaming simultaneously (a terabit is one trillion bits; there are eight bits in a byte). It is one of four such switches DE-CIX now runs at its Frankfurt exchange, which is spread across four data centres around the city. Between them they connect over a thousand networks, passing the packets making up video calls from one mobile-phone provider to another, or delivering data from TikTok to a local telecoms operator so that a German teenager can have their mind numbed by never-ending videos. 
Not every bit which goes online travels through an internet exchange. Some networks have direct links with each other, and some bits never leave the local network they started on. But as the internet has grown, so has its need for marvels like the super fridges of Frankfurt; DE-CIX now runs 40 exchanges around the world. They and hundreds of others like them make routing more straightforward, which conserves bandwidth (the measure of how much information a conduit such as an optical fibre or Wi-Fi channel can cope with), which in turn reduces the total “load” or burden put on computers and cables. They also do much to shrink the system’s latency, or the time it takes for a click or swipe on an internet-connected device to be communicated to another such device, whether it belongs to a human or sits in a data centre. 
The growing capacity and number of such exchanges, combined with the strategy of using CDNs to make sure lots of those exchanges have cached copies of the data their users most want immediate access to, have greatly enlarged the internet’s capacity to store and move data and at the same time have brought much of that data closer to its users. By doing so, they have enabled the internet to become what it is today. 
What many want of the internet tomorrow, though, will require more. Virtual and augmented realities such as those of “metaverses” need latencies far lower than those tolerated by applications now. That means bringing more of the internet’s capabilities closer to its “edge”—that is to say, the users. 
The edge is where the internet meets the real world. It is where data is produced and consumed. It is also where much of it is processed by the chips in phones and other devices, and for some uses that local processing power is more than adequate. For others, though—such as training AI models, weather forecasting and rendering animation and computer-graphics imaging for movies—the number-crunching capacity to be found in pockets, on laps and under desks is not enough. Hence the appeal of cloud-based computing, where numbers are crunched in data centres. 
Getting the data from the edge to specialist computing centres takes time, though. For applications which are computer-intensive but latency-insensitive, such as training AIs, that is fine. But what of applications which need both lots of computing and low latency? Today’s internet typically delivers latencies of about 65 milliseconds. Metaverses and self-driving cars need latencies of less than 20 milliseconds—quite possibly a lot less. That means distributing not just connectivity and data storage throughout the system but also increasing amounts of processing power, too. Without that, some applications which might be hugely popular, useful and lucrative will remain impractical. 
Directing traffic
Internet exchanges have reduced latency over the years by getting faster at moving information along. The most advanced switches in data centres can now handle 51 terabits per second. These switches are increasingly spreading out the load of moving data around, helping the internet as a whole function more efficiently. Cisco, a tech conglomerate, uses AI to predict the optimal times of day and routes for moving time-insensitive data, avoiding or minimising traffic jams that slow down networks.
There are ways to move data from place to place faster, too. Notably one can increase the speed at which light travels through fibre-optic cables by hollowing out their cores. Light, and thus information, travels nearly 50% faster through air than through standard glass. In December 2022 Microsoft acquired Lumenisity, a startup focused on hollow-core fibre technology, citing its “significant advantages” in increasing speed and reducing latency.
In theory, latency and load can both be reduced even more by doing some of the switching at the speed of light, too. Most switches, like most computers, are electronic. Packets of data travel along optical fibres in the form of light, or photons. Whenever such a packet passes through a switch—as it may do several times on its way from one user or server to another—it must flip-flop from photonic to electronic and back into photons again. The “transceivers” which perform these conversions use up time and, also important, energy. If switches were photonic instead, the data could make the entire trip in the form of photons. 
Switching costs
Photonic switches are a focus of research, but there are two main challenges to, er, switching to them. The first is inertia—nearly all routing protocols and software are designed for electronic systems, and they work. Changing to photonic systems would come at great cost and effort, and for now the benefits of doing so do not seem to be worth the trouble. The second challenge is that data encoded electronically is more tolerant of imperfections introduced in transmission (by, say, a faulty cable or external disruption). Setting a transistor to recognise a difference of 0.7 volts rather than one volt as a digital “one” leaves room for error without producing a “zero”; and when mistakes do get made, it is easy for an electronic switch to check and fix them, since they are literally binary.
But with light, data is encoded not in a pattern of binary numbers but instead along broad spectra of intensities, phases and polarisations. This approach demands far greater precision. One encoding strategy, for example, sends multiple streams of data in different wavelengths (colours) at the same time; a photonic switch would have to distinguish between different wavelengths and route them appropriately. Small errors would be extremely difficult to check and correct mid-transmission without slowing the process down enough to defeat the purpose of photonic switching. Errors could be fixed at the endpoint instead, but in the meantime tiny flaws would compound as they run through multiple photonic switches uncorrected.
One way to correct errors in the photonic domain is to send extra information in the packet, alongside the data, allowing the receiver at the other end to fix any distortions or alterations without the need for retransmission. Another is to use machine-learning algorithms to predict and correct errors. In the medium term, until further breakthroughs make purely photonic switching more realistic, hybrid systems might yield benefits from both worlds, combining the speed of photonics with the processing capabilities of electronics. This would work by, say, converting into ones and zeros only the header of the packet, which contains its shipping address, rather than the entire thing.
But in the near future the biggest reductions in latency and load will almost certainly come from upgrades to internet infrastructure on the edge. Early signs of the potential are being seen in CDNs and other distributed networks. Distributed networks have been integral to the growth of services like Netflix, TikTok and YouTube. They will also be absolutely essential to the internet of tomorrow. But for that to happen, CDNs (or their successors) need to do more thinking for themselves. 
For applications which generate a lot of data from sensors—like, say, autonomous vehicles, augmented-reality glasses or various real-time “smart city” applications—it makes sense to bring your computational heft as close as possible to the data, rather than lugging gigabytes of data to a central hub and back. A new generation of CDNs, or something like them—call them content  computation delivery networks—is beginning to spring up in spots all around the world, providing applications with the edge-computing services they require to work in real-time. 
Consider cloud gaming, through which players can access high-quality, high-resolution games without having to splurge on a high-end gaming computer. Companies provide this service by outsourcing computing tasks to servers. But if the servers are too far from users this can result in high latencies, leading to the most dreaded three-letter word in the gamer’s lexicon: lag. Major cloud providers with gaming platforms, like Meta and Nvidia, deal with this issue by renting space in lots of smaller data centres closer to the edge, greatly shortening the distance that most information has to travel between gamers and their games. (They are also building micro-data centres on the edge, but renting space is often more efficient.) This sort of solution will be especially important for augmented and virtual reality, where delays can lead to motion sickness and other sources of dissatisfaction. 
Through a glass lightly
It might also be possible to combine computing close to the edge with the speed increases offered by photonic switches. Researchers are exploring various circuits and materials to better manipulate photons at high speeds with high precision. 
Computing in light would speed things up in another way essential to the future of the internet: the development of AI. Training a neural network requires moving terabytes of data from storage to AI chips. Processing that data then requires moving it through the network, from (artificial) neuron to neuron, from layer to layer. Chips are now so fast, though, that it is currently not possible to feed them enough data quickly enough to fully take advantage of their processing capabilities. The speed of data transfer is capped by the physical limits of sending electrons over copper wires (the wires heat up, increasing resistance) or of converting photons into electrons and back. 
This is a similar challenge to that of switches. As with the study of , glass may provide the answer. The manner in which information is encoded in light makes it possible to do a particular type of maths (namely, matrix multiplication) by separating and recombining light waves. This happens to be the same maths that AI chips do when training or running neural networks. With the aid of tools such as mirrors, beam-splitters and wave guides, devices called interferometers can manipulate light in a way that performs these calculations. Doing this at scale would vastly increase the speed and efficiency at which AI chips—both the current electronic ones and future photonic chips—go through data. Further, once an AI model is trained, its architecture could be etched in glass and run entirely without a chip from, say, Nvidia.
All this would save a lot of time, heat (from both data transfer and chip processing) and energy. It would make the cloud far more robust, powerful and efficient than it is today. But that technology is speculative and, at best, a long way off yet (optical computing has been a dream for decades). In the meantime, the builders of the internet are working on other ways to make it whir more efficiently. Without such or similar advances the environmental consequences of the cloud will raise doubts about how well the planet can cope physically with the internet.■
